{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State)-> Literal [\"summarize_conversation\",END]:\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=\"Hi Lance! How's it going? What can I do for you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 33, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVEnt6YRGM2QciCAt8xk9AJ6lNlY4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--45a12ae0-1ee4-4f94-a172-66e0a823efb3-0', usage_metadata={'input_tokens': 33, 'output_tokens': 16, 'total_tokens': 49, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! It's great to meet you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How's it going? What can I do for you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 2: {'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 3: {'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 4: {'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 5: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 6: {'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 7: {'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 8: {'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 9: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 10: {'chunk': AIMessageChunk(content=' stor', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 11: {'chunk': AIMessageChunk(content='ied', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 12: {'chunk': AIMessageChunk(content=' franchise', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 13: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 14: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 15: {'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 16: {'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 17: {'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 18: {'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 19: {'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 20: {'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 21: {'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 22: {'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 23: {'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 24: {'chunk': AIMessageChunk(content=' rich', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 25: {'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 26: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 27: {'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 28: {'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 29: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 30: {'chunk': AIMessageChunk(content=' field', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 31: {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 32: {'chunk': AIMessageChunk(content=\" Here's\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 33: {'chunk': AIMessageChunk(content=' an', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 34: {'chunk': AIMessageChunk(content=' overview', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 35: {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 36: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 37: {'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 38: {'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 39: {'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 40: {'chunk': AIMessageChunk(content=' History', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 41: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 42: {'chunk': AIMessageChunk(content=' Background', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 43: {'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 44: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 45: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 46: {'chunk': AIMessageChunk(content='Founded', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 47: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 48: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 49: {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 50: {'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 51: {'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 52: {'chunk': AIMessageChunk(content=' established', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 53: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 54: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 55: {'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 56: {'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 57: {'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 58: {'chunk': AIMessageChunk(content=' part', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 59: {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 60: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 61: {'chunk': AIMessageChunk(content=' All', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 62: {'chunk': AIMessageChunk(content='-Amer', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 63: {'chunk': AIMessageChunk(content='ica', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 64: {'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 65: {'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 66: {'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 67: {'chunk': AIMessageChunk(content='AA', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 68: {'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 69: {'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 70: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 71: {'chunk': AIMessageChunk(content=' joined', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 72: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 73: {'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 74: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 75: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 76: {'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 77: {'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 78: {'chunk': AIMessageChunk(content=' when', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 79: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 80: {'chunk': AIMessageChunk(content=' leagues', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 81: {'chunk': AIMessageChunk(content=' merged', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 82: {'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 83: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 84: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 85: {'chunk': AIMessageChunk(content='Location', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 86: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 87: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 88: {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 89: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 90: {'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 91: {'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 92: {'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 93: {'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 94: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 95: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 96: {'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 97: {'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 98: {'chunk': AIMessageChunk(content=' Bay', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 99: {'chunk': AIMessageChunk(content=' Area', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 100: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 101: {'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 102: {'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 103: {'chunk': AIMessageChunk(content=' current', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 104: {'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 105: {'chunk': AIMessageChunk(content=' stadium', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 106: {'chunk': AIMessageChunk(content=' being', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 107: {'chunk': AIMessageChunk(content=' Levi', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 108: {'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 109: {'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 110: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 111: {'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 112: {'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 113: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 114: {'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 115: {'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 116: {'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 117: {'chunk': AIMessageChunk(content=' Ach', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 118: {'chunk': AIMessageChunk(content='ievements', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 119: {'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 120: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 121: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 122: {'chunk': AIMessageChunk(content='Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 123: {'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 124: {'chunk': AIMessageChunk(content=' Championships', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 125: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 126: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 127: {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 128: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 129: {'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 130: {'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 131: {'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 132: {'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 133: {'chunk': AIMessageChunk(content=' five', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 134: {'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 135: {'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 136: {'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 137: {'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 138: {'chunk': AIMessageChunk(content='Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 139: {'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 140: {'chunk': AIMessageChunk(content=' XVI', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 141: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 142: {'chunk': AIMessageChunk(content=' XIX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 143: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 144: {'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 145: {'chunk': AIMessageChunk(content='III', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 146: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 147: {'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 148: {'chunk': AIMessageChunk(content='IV', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 149: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 150: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 151: {'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 152: {'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 153: {'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 154: {'chunk': AIMessageChunk(content=' primarily', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 155: {'chunk': AIMessageChunk(content=' during', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 156: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 157: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 158: {'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 159: {'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 160: {'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 161: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 162: {'chunk': AIMessageChunk(content=' early', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 163: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 164: {'chunk': AIMessageChunk(content='199', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 165: {'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 166: {'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 167: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 168: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 169: {'chunk': AIMessageChunk(content=' period', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 170: {'chunk': AIMessageChunk(content=' marked', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 171: {'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 172: {'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 173: {'chunk': AIMessageChunk(content=' dominance', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 174: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 175: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 176: {'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 177: {'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 178: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 179: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 180: {'chunk': AIMessageChunk(content='Conference', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 181: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 182: {'chunk': AIMessageChunk(content=' Division', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 183: {'chunk': AIMessageChunk(content=' Titles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 184: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 185: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 186: {'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 187: {'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 188: {'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 189: {'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 190: {'chunk': AIMessageChunk(content=' NFC', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 191: {'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 192: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 193: {'chunk': AIMessageChunk(content=' NFC', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 194: {'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 195: {'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 196: {'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 197: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 198: {'chunk': AIMessageChunk(content=' establishing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 199: {'chunk': AIMessageChunk(content=' themselves', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 200: {'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 201: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 202: {'chunk': AIMessageChunk(content=' perennial', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 203: {'chunk': AIMessageChunk(content=' contender', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 204: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 205: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 206: {'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 207: {'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 208: {'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 209: {'chunk': AIMessageChunk(content=' Not', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 210: {'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 211: {'chunk': AIMessageChunk(content=' Figures', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 212: {'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 213: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 214: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 215: {'chunk': AIMessageChunk(content='Players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 216: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 217: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 218: {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 219: {'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 220: {'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 221: {'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 222: {'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 223: {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 224: {'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 225: {'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 226: {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 227: {'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 228: {'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 229: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 230: {'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 231: {'chunk': AIMessageChunk(content=':\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 232: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 233: {'chunk': AIMessageChunk(content=' -', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 234: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 235: {'chunk': AIMessageChunk(content='Joe', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 236: {'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 237: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 238: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 239: {'chunk': AIMessageChunk(content=' Legendary', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 240: {'chunk': AIMessageChunk(content=' quarterback', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 241: {'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 242: {'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 243: {'chunk': AIMessageChunk(content=' his', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 244: {'chunk': AIMessageChunk(content=' po', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 245: {'chunk': AIMessageChunk(content='ise', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 246: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 247: {'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 248: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 249: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 250: {'chunk': AIMessageChunk(content=' postseason', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 251: {'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 252: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 253: {'chunk': AIMessageChunk(content=' -', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 254: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 255: {'chunk': AIMessageChunk(content='Jerry', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 256: {'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 257: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 258: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 259: {'chunk': AIMessageChunk(content=' Wid', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 260: {'chunk': AIMessageChunk(content='ely', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 261: {'chunk': AIMessageChunk(content=' regarded', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 262: {'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 263: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 264: {'chunk': AIMessageChunk(content=' greatest', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 265: {'chunk': AIMessageChunk(content=' wide', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 266: {'chunk': AIMessageChunk(content=' receiver', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 267: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 268: {'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 269: {'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 270: {'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 271: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 272: {'chunk': AIMessageChunk(content=' -', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 273: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 274: {'chunk': AIMessageChunk(content='Steve', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 275: {'chunk': AIMessageChunk(content=' Young', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 276: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 277: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 278: {'chunk': AIMessageChunk(content=' Another', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 279: {'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 280: {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 281: {'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 282: {'chunk': AIMessageChunk(content=' quarterback', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 283: {'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 284: {'chunk': AIMessageChunk(content=' succeeded', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 285: {'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 286: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 287: {'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 288: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 289: {'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 290: {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 291: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 292: {'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 293: {'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 294: {'chunk': AIMessageChunk(content=' victory', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 295: {'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 296: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 297: {'chunk': AIMessageChunk(content=' -', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 298: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 299: {'chunk': AIMessageChunk(content='Ron', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 300: {'chunk': AIMessageChunk(content='nie', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 301: {'chunk': AIMessageChunk(content=' L', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 302: {'chunk': AIMessageChunk(content='ott', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 303: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 304: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 305: {'chunk': AIMessageChunk(content=' Ren', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 306: {'chunk': AIMessageChunk(content='owned', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 307: {'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 308: {'chunk': AIMessageChunk(content=' his', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 309: {'chunk': AIMessageChunk(content=' hard', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 310: {'chunk': AIMessageChunk(content='-h', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 311: {'chunk': AIMessageChunk(content='itting', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 312: {'chunk': AIMessageChunk(content=' style', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 313: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 314: {'chunk': AIMessageChunk(content=' versatility', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 315: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 316: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 317: {'chunk': AIMessageChunk(content=' secondary', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 318: {'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 319: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 320: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 321: {'chunk': AIMessageChunk(content='Co', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 322: {'chunk': AIMessageChunk(content='aches', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 323: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 324: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 325: {'chunk': AIMessageChunk(content=' \\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 326: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 327: {'chunk': AIMessageChunk(content=' -', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 328: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 329: {'chunk': AIMessageChunk(content='Bill', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 330: {'chunk': AIMessageChunk(content=' Walsh', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 331: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 332: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 333: {'chunk': AIMessageChunk(content=' Innov', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 334: {'chunk': AIMessageChunk(content='ator', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 335: {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 336: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 337: {'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 338: {'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 339: {'chunk': AIMessageChunk(content=' offense', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 340: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 341: {'chunk': AIMessageChunk(content=' leading', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 342: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 343: {'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 344: {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 345: {'chunk': AIMessageChunk(content=' three', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 346: {'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 347: {'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 348: {'chunk': AIMessageChunk(content=' victories', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 349: {'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 350: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 351: {'chunk': AIMessageChunk(content=' -', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 352: {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 353: {'chunk': AIMessageChunk(content='George', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 354: {'chunk': AIMessageChunk(content=' Se', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 355: {'chunk': AIMessageChunk(content='if', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 356: {'chunk': AIMessageChunk(content='ert', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 357: {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 358: {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 359: {'chunk': AIMessageChunk(content=' Continued', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 360: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 361: {'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 362: {'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 363: {'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 364: {'chunk': AIMessageChunk(content=' two', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 365: {'chunk': AIMessageChunk(content=' more', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 366: {'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 367: {'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 368: {'chunk': AIMessageChunk(content=' wins', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 369: {'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 370: {'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 371: {'chunk': AIMessageChunk(content=' Rival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 372: {'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 373: {'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 374: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 375: {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 376: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 377: {'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 378: {'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 379: {'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 380: {'chunk': AIMessageChunk(content=' intense', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 381: {'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 382: {'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 383: {'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 384: {'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 385: {'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 386: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 387: {'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 388: {'chunk': AIMessageChunk(content=' notably', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 389: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 390: {'chunk': AIMessageChunk(content=' Dallas', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 391: {'chunk': AIMessageChunk(content=' Cowboys', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 392: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 393: {'chunk': AIMessageChunk(content=' Los', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 394: {'chunk': AIMessageChunk(content=' Angeles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 395: {'chunk': AIMessageChunk(content=' Rams', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 396: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 397: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 398: {'chunk': AIMessageChunk(content=' Seattle', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 399: {'chunk': AIMessageChunk(content=' Seahawks', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 400: {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 401: {'chunk': AIMessageChunk(content=' These', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 402: {'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 403: {'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 404: {'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 405: {'chunk': AIMessageChunk(content=' fueled', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 406: {'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 407: {'chunk': AIMessageChunk(content=' historic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 408: {'chunk': AIMessageChunk(content=' playoff', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 409: {'chunk': AIMessageChunk(content=' battles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 410: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 411: {'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 412: {'chunk': AIMessageChunk(content=' divis', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 413: {'chunk': AIMessageChunk(content='ional', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 414: {'chunk': AIMessageChunk(content=' match', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 415: {'chunk': AIMessageChunk(content='ups', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 416: {'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 417: {'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 418: {'chunk': AIMessageChunk(content=' Recent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 419: {'chunk': AIMessageChunk(content=' Performance', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 420: {'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 421: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 422: {'chunk': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 423: {'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 424: {'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 425: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 426: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 427: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 428: {'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 429: {'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 430: {'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 431: {'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 432: {'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 433: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 434: {'chunk': AIMessageChunk(content=' reaching', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 435: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 436: {'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 437: {'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 438: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 439: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 440: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 441: {'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 442: {'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 443: {'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 444: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 445: {'chunk': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 446: {'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 447: {'chunk': AIMessageChunk(content=' were', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 448: {'chunk': AIMessageChunk(content=' narrowly', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 449: {'chunk': AIMessageChunk(content=' defeated', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 450: {'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 451: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 452: {'chunk': AIMessageChunk(content=' Kansas', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 453: {'chunk': AIMessageChunk(content=' City', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 454: {'chunk': AIMessageChunk(content=' Chiefs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 455: {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 456: {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 457: {'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 458: {'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 459: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 460: {'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 461: {'chunk': AIMessageChunk(content=' roster', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 462: {'chunk': AIMessageChunk(content=' featuring', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 463: {'chunk': AIMessageChunk(content=' standout', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 464: {'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 465: {'chunk': AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 466: {'chunk': AIMessageChunk(content=' George', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 467: {'chunk': AIMessageChunk(content=' K', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 468: {'chunk': AIMessageChunk(content='ittle', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 469: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 470: {'chunk': AIMessageChunk(content=' Nick', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 471: {'chunk': AIMessageChunk(content=' B', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 472: {'chunk': AIMessageChunk(content='osa', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 473: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 474: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 475: {'chunk': AIMessageChunk(content=' De', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 476: {'chunk': AIMessageChunk(content='ebo', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 477: {'chunk': AIMessageChunk(content=' Samuel', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 478: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 479: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 480: {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 481: {'chunk': AIMessageChunk(content=' coached', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 482: {'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 483: {'chunk': AIMessageChunk(content=' Kyle', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 484: {'chunk': AIMessageChunk(content=' Shan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 485: {'chunk': AIMessageChunk(content='ahan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 486: {'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 487: {'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 488: {'chunk': AIMessageChunk(content=' Team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 489: {'chunk': AIMessageChunk(content=' Culture', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 490: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 491: {'chunk': AIMessageChunk(content=' Legacy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 492: {'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 493: {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 494: {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 495: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 496: {'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 497: {'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 498: {'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 499: {'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 500: {'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 501: {'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 502: {'chunk': AIMessageChunk(content=' innovative', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 503: {'chunk': AIMessageChunk(content=' offensive', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 504: {'chunk': AIMessageChunk(content=' strategies', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 505: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 506: {'chunk': AIMessageChunk(content=' particularly', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 507: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 508: {'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 509: {'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 510: {'chunk': AIMessageChunk(content=' offense', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 511: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 512: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 513: {'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 514: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 515: {'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 516: {'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 517: {'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 518: {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 519: {'chunk': AIMessageChunk(content=' Their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 520: {'chunk': AIMessageChunk(content=' legacy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 521: {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 522: {'chunk': AIMessageChunk(content=' built', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 523: {'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 524: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 525: {'chunk': AIMessageChunk(content=' tradition', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 526: {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 527: {'chunk': AIMessageChunk(content=' excellence', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 528: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 529: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 530: {'chunk': AIMessageChunk(content=' commitment', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 531: {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 532: {'chunk': AIMessageChunk(content=' winning', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 533: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 534: {'chunk': AIMessageChunk(content=' making', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 535: {'chunk': AIMessageChunk(content=' them', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 536: {'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 537: {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 538: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 539: {'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 540: {'chunk': AIMessageChunk(content=' respected', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 541: {'chunk': AIMessageChunk(content=' franchises', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 542: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 543: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 544: {'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 545: {'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 546: {'chunk': AIMessageChunk(content='Overall', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 547: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 548: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 549: {'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 550: {'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 551: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 552: {'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 553: {'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 554: {'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 555: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 556: {'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 557: {'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 558: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 559: {'chunk': AIMessageChunk(content=' rich', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 560: {'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 561: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 562: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 563: {'chunk': AIMessageChunk(content=' tradition', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 564: {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 565: {'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 566: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 567: {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 568: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 569: {'chunk': AIMessageChunk(content=' bright', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 570: {'chunk': AIMessageChunk(content=' future', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 571: {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 572: {'chunk': AIMessageChunk(content=' continuing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 573: {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 574: {'chunk': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 575: {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 576: {'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 577: {'chunk': AIMessageChunk(content=' presence', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 578: {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 579: {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 580: {'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 581: {'chunk': AIMessageChunk(content=' landscape', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 582: {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2')}\n",
      "Chunk 583: {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2', chunk_position='last')}\n",
      "Chunk 584: {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2', usage_metadata={'input_tokens': 508, 'output_tokens': 581, 'total_tokens': 1089, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "Chunk 585: {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--2248eb93-f588-4764-b5c4-6573389bd4a2', chunk_position='last')}\n",
      "\n",
      "Total streamed chunks: 585\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "\n",
    "token_count = 0  \n",
    "\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        token_count += 1  # Added: increment counter\n",
    "        print(f\"Chunk {token_count}: {data}\")  # Added: formatted output\n",
    "\n",
    "print(f\"\\nTotal streamed chunks: {token_count}\")  # Added: summary after loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| San| Francisco| |49|ers| are| a| professional| American| football| team| based| in| the| San| Francisco| Bay| Area|.| They| are| a| member| of| the| National| Football| League| (|NFL|)| and| compete| in| the| league|'s| National| Football| Conference| (|N|FC|)| West| division|.| Here| are| some| key| points| about| the| team|:\n",
      "\n",
      "|1|.| **|History| and| Establish|ment|**|:| The| |49|ers| were| established| in| |194|6| as| a| charter| member| of| the| All|-Amer|ica| Football| Conference| (|AA|FC|)| and| joined| the| NFL| in| |194|9| when| the| leagues| merged|.| They| are| the| |10|th| oldest| franchise| in| the| NFL| and| the| oldest| major| professional| sports| team| in| California|.\n",
      "\n",
      "|2|.| **|Team| Name| and| Colors|**|:| The| team| is| named| after| the| prospect|ors| who| arrived| in| Northern| California| during| the| |184|9| Gold| Rush|.| The| team's| colors| are| red|,| gold|,| and| white|.\n",
      "\n",
      "|3|.| **|St|adium|**|:| The| |49|ers| play| their| home| games| at| Levi|'s| Stadium| in| Santa| Clara|,| California|,| which| opened| in| |201|4|.| Before| that|,| they| played| at| Cand|lestick| Park| in| San| Francisco| from| |197|1| to| |201|3|.\n",
      "\n",
      "|4|.| **|Champ|ionship|s| and| Success|**|:| The| |49|ers| have| won| five| Super| Bowl| championships| (|in| the| |198|1|,| |198|4|,| |198|8|,| |198|9|,| and| |199|4| seasons|),| making| them| one| of| the| most| successful| teams| in| NFL| history|.| They| have| also| won| numerous| division| titles| and| conference| championships|.\n",
      "\n",
      "|5|.| **|Not|able| Figures|**|:| The| team| has| had| several| Hall| of| Fame| players| and| coaches|,| including| Joe| Montana|,| Jerry| Rice|,| Steve| Young|,| Ronnie| L|ott|,| and| coach| Bill| Walsh|.| Walsh| is| credited| with| popular|izing| the| \"|West| Coast| offense|,\"| a| style| of| play| that| emphasizes| short|,| horizontal| passing| routes|.\n",
      "\n",
      "|6|.| **|R|ival|ries|**|:| The| |49|ers| have| several| notable| rival|ries|,| particularly| with| the| Dallas| Cowboys|,| Green| Bay| Packers|,| and| within| their| division|,| the| Seattle| Seahawks|,| Los| Angeles| Rams|,| and| Arizona| Cardinals|.\n",
      "\n",
      "|7|.| **|Recent| Performance|**|:| In| recent| years|,| the| |49|ers| have| experienced| both| ups| and| downs|.| They| reached| the| Super| Bowl| in| the| |201|9| season| but| lost| to| the| Kansas| City| Chiefs|.| The| team| has| been| competitive| in| the| NFC| West| and| has| made| several| playoff| appearances|.\n",
      "\n",
      "|8|.| **|Community| and| Culture|**|:| The| |49|ers| have| a| strong| fan| base| and| are| known| for| their| community| involvement| and| charitable| activities|.| The| team| has| a| rich| history| and| a| legacy| of| success| that| has| contributed| to| a| passionate| following|.\n",
      "\n",
      "|The| |49|ers| continue| to| be| a| prominent| team| in| the| NFL|,| with| a| focus| on| building| a| competitive| roster| and| striving| for| future| championships|.||||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "-  API: http://127.0.0.1:2024\n",
    "-  Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "-  API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '019a25c7-cf4e-72f2-8c58-20310a00aad7', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4a0b14fb-1561-4292-9b4d-01451d8a5caa', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4a0b14fb-1561-4292-9b4d-01451d8a5caa', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_aX1e18NGgFbDWGd3XhlyByQQ', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVHETuxhyIlpXvNrt6KXUjUFYHh32', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--1ae1c38c-300c-461d-be74-8022083d123d-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_aX1e18NGgFbDWGd3XhlyByQQ', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4a0b14fb-1561-4292-9b4d-01451d8a5caa', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_aX1e18NGgFbDWGd3XhlyByQQ', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVHETuxhyIlpXvNrt6KXUjUFYHh32', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--1ae1c38c-300c-461d-be74-8022083d123d-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_aX1e18NGgFbDWGd3XhlyByQQ', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'd436c9db-1523-47c8-8669-68df2d74031b', 'tool_call_id': 'call_aX1e18NGgFbDWGd3XhlyByQQ', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4a0b14fb-1561-4292-9b4d-01451d8a5caa', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_aX1e18NGgFbDWGd3XhlyByQQ', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVHETuxhyIlpXvNrt6KXUjUFYHh32', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--1ae1c38c-300c-461d-be74-8022083d123d-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_aX1e18NGgFbDWGd3XhlyByQQ', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'd436c9db-1523-47c8-8669-68df2d74031b', 'tool_call_id': 'call_aX1e18NGgFbDWGd3XhlyByQQ', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVHEU4dC7FQaz2CCc1QgCnzwqaNc8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--6ce10874-b599-4ded-9734-be35dcb13a55-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='c3ec872a-99a1-4eec-bcb6-a04973f48ac5'\n",
      "=========================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f64f290af2', 'id': 'chatcmpl-CSqw6HYoyCI7z2AuKAAfSTQGbvzla', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--c91028e7-7a0a-4746-a4f5-edcff5380abc-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_AFChrxIQGbr7mmzr8buxymY0', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='f69a844b-5f82-4256-96dd-92b044e888d9' tool_call_id='call_AFChrxIQGbr7mmzr8buxymY0'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb3c3cb84d', 'id': 'chatcmpl-CSqw7xBeinGuHlx0upkmo2tryppco', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--dba1c4af-ed8f-4fed-8770-2c3429603cd0-0'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 019a0358-57dc-76f9-bc63-633eee467a86\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata and response_metadata.get(\"finish_reason\"):\n",
    "                    print(f\"Response Metadata: Finish Reason - {response_metadata['finish_reason']}\")                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
